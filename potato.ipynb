{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import pandas as pd \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\desai\\OneDrive\\Desktop\\CNN project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "current_directory = os.getcwd()\n",
    "train_path = os.path.join(current_directory, \"dataset\",\"Train\")\n",
    "valid_path = os.path.join(current_directory, \"dataset\",\"Valid\")\n",
    "test_path = os.path.join(current_directory, \"dataset\",\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 900 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    # batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    # seed=None,\n",
    "    # validation_split=None,\n",
    "    # subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    # follow_links=False,\n",
    "    # crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    valid_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    # batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    # seed=None,\n",
    "    # validation_split=None,\n",
    "    # subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    # follow_links=False,\n",
    "    # crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "testing_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    # batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    # seed=None,\n",
    "    # validation_split=None,\n",
    "    # subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    # follow_links=False,\n",
    "    # crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shape=[128,128,3]))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(units=1500,activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=3,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 126, 126, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 63, 63, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 61, 61, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 6, 6, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 2, 2, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1500)              3073500   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1500)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 4503      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7790227 (29.72 MB)\n",
      "Trainable params: 7790227 (29.72 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\desai\\OneDrive\\Desktop\\CNN project\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\desai\\OneDrive\\Desktop\\CNN project\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "29/29 [==============================] - 25s 734ms/step - loss: 1.2014 - accuracy: 0.3800 - val_loss: 1.0266 - val_accuracy: 0.6200\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 19s 636ms/step - loss: 0.9043 - accuracy: 0.5700 - val_loss: 0.8494 - val_accuracy: 0.6333\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 18s 617ms/step - loss: 0.6612 - accuracy: 0.6900 - val_loss: 0.4996 - val_accuracy: 0.8033\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 18s 608ms/step - loss: 0.4130 - accuracy: 0.8400 - val_loss: 0.2542 - val_accuracy: 0.8833\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 18s 610ms/step - loss: 0.2844 - accuracy: 0.8833 - val_loss: 0.1978 - val_accuracy: 0.9100\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 18s 609ms/step - loss: 0.2132 - accuracy: 0.9122 - val_loss: 0.1539 - val_accuracy: 0.9333\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 18s 603ms/step - loss: 0.2056 - accuracy: 0.9244 - val_loss: 0.2269 - val_accuracy: 0.9033\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 18s 602ms/step - loss: 0.1830 - accuracy: 0.9300 - val_loss: 0.1641 - val_accuracy: 0.9333\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 18s 604ms/step - loss: 0.1460 - accuracy: 0.9511 - val_loss: 0.2255 - val_accuracy: 0.9133\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 17s 601ms/step - loss: 0.1937 - accuracy: 0.9211 - val_loss: 0.1350 - val_accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "training_history = cnn.fit(x=training_set,validation_data=validation_set,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 4s 134ms/step - loss: 0.0866 - accuracy: 0.9622\n",
      "Training accuracy: 0.9622222185134888\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = cnn.evaluate(training_set)\n",
    "print('Training accuracy:',train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 142ms/step - loss: 0.1350 - accuracy: 0.9400\n",
      "Validation accuracy: 0.9399999976158142\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = cnn.evaluate(validation_set)\n",
    "print('Validation accuracy:',val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('trained_plant_disease_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_path = \"dataset/Train\"\n",
    "class_labels = sorted(os.listdir(train_path))\n",
    "print(class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model File Size: 93568720\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Model File Size:\", os.path.getsize(\"trained_plant_disease_model.keras\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Path: c:\\Users\\desai\\OneDrive\\Desktop\\CNN project\\trained_plant_disease_model.keras\n",
      "Model Loaded Successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "model_path = os.path.abspath(\"trained_plant_disease_model.keras\")\n",
    "print(\"Model Path:\", model_path)\n",
    "\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "print(\"Model Loaded Successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Loaded Successfully\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_path = \"trained_plant_disease_model.keras\"\n",
    "\n",
    "try:\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print(\"✅ Model Loaded Successfully\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Error Loading Model:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_plant_disease_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_plant_disease_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(\"trained_plant_disease_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_path, compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
